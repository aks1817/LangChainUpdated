{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b27691",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39451fd5",
   "metadata": {},
   "source": [
    "Models can request to call tools that perform tasks such as fetching data from database, searching the web, or runing code. Tools are pairing of:\n",
    " * A schema, including the name of the tool, a description, and/or argument definitions (often a JSON schema) \n",
    " * A function or coroutine to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c88b5cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nHmm, the user said 'Hello, how are you?'. I should respond warmly and politely. First, I need to acknowledge their greeting. Then, I can express my state of being (as an AI, I don't have real feelings, but I can respond in a friendly way). Next, I should show interest in the user by asking how they're doing. Also, I need to let them know I'm here to help. The tone should be friendly and approachable, not too formal. Maybe add an emoji to make it more lively. Keep the response concise but not too short. Make sure to follow the rules of being helpful and friendly. Alright, that should cover it.\\n</think>\\n\\nHello! I'm doing well, thank you for asking! üòä How can I assist you today? I'm always here to help with any questions or tasks you might have. What's on your mind?\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "model=init_chat_model(\"groq:qwen/qwen3-32b\")\n",
    "\n",
    "## invoke the model\n",
    "response=model.invoke(\"Hello, how are you?\")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fe53284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_current_weather(location: str) -> str:\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    return f\"The current weather in {location} is 72 degrees and sunny.\"\n",
    "\n",
    "model_with_tools = model.bind_tools([get_current_weather])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7097ecdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking about the weather in New York. I need to use the get_current_weather function. Let me check the function parameters. It requires a location, which is provided as \"New York\". So I\\'ll call the function with that location. Make sure the JSON is correctly formatted with the name and arguments.\\n', 'tool_calls': [{'id': 'tykm4a7x7', 'function': {'arguments': '{\"location\":\"New York\"}', 'name': 'get_current_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 92, 'prompt_tokens': 158, 'total_tokens': 250, 'completion_time': 0.134046757, 'completion_tokens_details': {'reasoning_tokens': 66}, 'prompt_time': 0.006350988, 'prompt_tokens_details': None, 'queue_time': 0.159700272, 'total_time': 0.140397745}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_2bfcc54d36', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019be069-6444-74d0-8b85-52e646af6dcb-0', tool_calls=[{'name': 'get_current_weather', 'args': {'location': 'New York'}, 'id': 'tykm4a7x7', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 158, 'output_tokens': 92, 'total_tokens': 250, 'output_token_details': {'reasoning': 66}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model_with_tools.invoke(\"What's the weather like in New York?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2591ce34",
   "metadata": {},
   "source": [
    "### Tool Execution Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e296404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in New York is **72 degrees** and **sunny**. Let me know if you'd like more details! ‚òÄÔ∏è\n"
     ]
    }
   ],
   "source": [
    "tools = {\n",
    "    \"get_current_weather\": get_current_weather\n",
    "}\n",
    "\n",
    "# Step 1: Model generates tool calls\n",
    "messages= [{\"role\": \"user\", \"content\": \"What's the weather like in New York?\"}]\n",
    "ai_message = model_with_tools.invoke(messages)\n",
    "messages.append(ai_message)\n",
    "\n",
    "#Step 2: Execute tool calls and collect tool results\n",
    "for tool_call in ai_message.tool_calls:\n",
    "    tool_name = tool_call[\"name\"]\n",
    "    tool_args = tool_call[\"args\"]\n",
    "    tool_fn = tools[tool_name]\n",
    "    tool_result=tool_fn.invoke(tool_call)\n",
    "    messages.append({\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_call_id\": tool_call[\"id\"],\n",
    "        \"content\": tool_result\n",
    "    })\n",
    "\n",
    "#Step 3: Pass results back to model to generate final response\n",
    "final_response=model_with_tools.invoke(messages)\n",
    "print(final_response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChainUpdated",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
